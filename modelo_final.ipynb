{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a85f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, fbeta_score, f1_score, precision_score, recall_score, average_precision_score, balanced_accuracy_score, matthews_corrcoef, precision_recall_curve, ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63d308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ibm_hr_dataset(n_samples=1_000_000, seed=42):\n",
    "    \"\"\"\n",
    "    Gera um dataset sintético inspirado no IBM HR Analytics com relações mais realistas\n",
    " \n",
    "    Parameters:\n",
    "    n_samples (int): Número de amostras a gerar\n",
    "    seed (int): Seed para reprodutibilidade\n",
    " \n",
    "    Returns:\n",
    "    pd.DataFrame: Dataset gerado\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    " \n",
    "    # Gerando dados base\n",
    "    data = {}\n",
    " \n",
    "    # Idade com distribuição mais realista (concentrada entre 25-50 anos)\n",
    "    data['Age'] = np.random.normal(38, 10, n_samples).astype(int)\n",
    "    data['Age'] = np.clip(data['Age'], 18, 65)\n",
    " \n",
    "    # Gênero\n",
    "    data['Gender'] = np.random.choice(['Female', 'Male'], n_samples, p=[0.4, 0.6])\n",
    " \n",
    "    # Educação (1-5: Below College, College, Bachelor, Master, Doctor)\n",
    "    education_probs = [0.05, 0.15, 0.40, 0.30, 0.10]\n",
    "    data['Education'] = np.random.choice([1, 2, 3, 4, 5], n_samples, p=education_probs)\n",
    " \n",
    "    # Campo educacional baseado no nível de educação\n",
    "    education_fields = ['Life Sciences', 'Other', 'Medical', 'Marketing', 'Technical Degree', 'Human Resources']\n",
    "    data['EducationField'] = np.random.choice(education_fields, n_samples)\n",
    " \n",
    "    # Departamento\n",
    "    dept_probs = [0.45, 0.40, 0.15]  # Sales mais comum, HR menos comum\n",
    "    data['Department'] = np.random.choice(['Sales', 'Research & Development', 'Human Resources'],\n",
    "                                        n_samples, p=dept_probs)\n",
    " \n",
    "    # Job Role baseado no departamento\n",
    "    job_roles = {\n",
    "        'Sales': ['Sales Executive', 'Sales Representative', 'Manager'],\n",
    "        'Research & Development': ['Research Scientist', 'Laboratory Technician', 'Research Director', 'Manager'],\n",
    "        'Human Resources': ['Human Resources', 'Manager']\n",
    "    }\n",
    " \n",
    "    data['JobRole'] = np.empty(n_samples, dtype=object)\n",
    "    for dept in job_roles:\n",
    "        mask = np.array(data['Department']) == dept\n",
    "        n_dept = mask.sum()\n",
    "        if n_dept > 0:\n",
    "            data['JobRole'][mask] = np.random.choice(job_roles[dept], n_dept)\n",
    " \n",
    "    # Job Level correlacionado com idade e educação\n",
    "    base_level = np.ones(n_samples)\n",
    "    age_bonus = (np.array(data['Age']) - 18) / 47 * 2  # 0-2 pontos baseado na idade\n",
    "    edu_bonus = (np.array(data['Education']) - 1) / 4 * 2  # 0-2 pontos baseado na educação\n",
    " \n",
    "    data['JobLevel'] = np.round(base_level + age_bonus + edu_bonus).astype(int)\n",
    "    data['JobLevel'] = np.clip(data['JobLevel'], 1, 5)\n",
    " \n",
    "    # Total Working Years correlacionado com idade\n",
    "    data['TotalWorkingYears'] = np.maximum(0, data['Age'] - 18 - np.random.randint(0, 5, n_samples))\n",
    " \n",
    "    # Years at Company (não pode ser maior que TotalWorkingYears)\n",
    "    data['YearsAtCompany'] = np.random.randint(0, 21, n_samples)\n",
    "    data['YearsAtCompany'] = np.minimum(data['YearsAtCompany'], data['TotalWorkingYears'])\n",
    " \n",
    "    # Years in Current Role (não pode ser maior que YearsAtCompany)\n",
    "    data['YearsInCurrentRole'] = np.random.randint(0, 11, n_samples)\n",
    "    data['YearsInCurrentRole'] = np.minimum(data['YearsInCurrentRole'], data['YearsAtCompany'])\n",
    " \n",
    "    # Years Since Last Promotion\n",
    "    data['YearsSinceLastPromotion'] = np.random.randint(0, 8, n_samples)\n",
    "    data['YearsSinceLastPromotion'] = np.minimum(data['YearsSinceLastPromotion'], data['YearsAtCompany'])\n",
    " \n",
    "    # Years With Current Manager\n",
    "    data['YearsWithCurrManager'] = np.random.randint(0, 8, n_samples)\n",
    "    data['YearsWithCurrManager'] = np.minimum(data['YearsWithCurrManager'], data['YearsInCurrentRole'])\n",
    " \n",
    "    # Número de empresas trabalhadas (correlacionado com anos totais de trabalho)\n",
    "    max_companies = np.minimum(data['TotalWorkingYears'] // 2, 9)\n",
    "    data['NumCompaniesWorked'] = np.array([np.random.randint(0, max(1, mc) + 1) for mc in max_companies])\n",
    " \n",
    "    # Monthly Income correlacionado com JobLevel, Education e TotalWorkingYears\n",
    "    base_income = 2000\n",
    "    level_factor = data['JobLevel'] * 2000\n",
    "    education_factor = data['Education'] * 500\n",
    "    experience_factor = data['TotalWorkingYears'] * 100\n",
    "    noise = np.random.normal(0, 1000, n_samples)\n",
    " \n",
    "    data['MonthlyIncome'] = base_income + level_factor + education_factor + experience_factor + noise\n",
    "    data['MonthlyIncome'] = np.clip(data['MonthlyIncome'].astype(int), 1000, 20000)\n",
    " \n",
    "    # Rates\n",
    "    data['DailyRate'] = np.random.randint(100, 1500, n_samples)\n",
    "    data['HourlyRate'] = np.random.randint(30, 100, n_samples)\n",
    "    data['MonthlyRate'] = np.random.randint(2000, 27000, n_samples)\n",
    " \n",
    "    # Distance from home (distribuição exponencial - mais pessoas moram perto)\n",
    "    data['DistanceFromHome'] = np.random.exponential(7, n_samples).astype(int) + 1\n",
    "    data['DistanceFromHome'] = np.clip(data['DistanceFromHome'], 1, 29)\n",
    " \n",
    "    # Business Travel\n",
    "    travel_probs = [0.70, 0.20, 0.10]  # Maioria viaja raramente\n",
    "    data['BusinessTravel'] = np.random.choice(['Travel_Rarely', 'Travel_Frequently', 'Non-Travel'],\n",
    "                                            n_samples, p=travel_probs)\n",
    " \n",
    "    # Satisfação e envolvimento\n",
    "    data['EnvironmentSatisfaction'] = np.random.choice([1, 2, 3, 4], n_samples, p=[0.10, 0.20, 0.40, 0.30])\n",
    "    data['JobSatisfaction'] = np.random.choice([1, 2, 3, 4], n_samples, p=[0.10, 0.20, 0.40, 0.30])\n",
    "    data['RelationshipSatisfaction'] = np.random.choice([1, 2, 3, 4], n_samples, p=[0.10, 0.20, 0.40, 0.30])\n",
    "    data['JobInvolvement'] = np.random.choice([1, 2, 3, 4], n_samples, p=[0.05, 0.15, 0.50, 0.30])\n",
    "    data['WorkLifeBalance'] = np.random.choice([1, 2, 3, 4], n_samples, p=[0.10, 0.25, 0.45, 0.20])\n",
    " \n",
    "    # Performance Rating (maioria boa performance)\n",
    "    data['PerformanceRating'] = np.random.choice([3, 4], n_samples, p=[0.84, 0.16])\n",
    " \n",
    "    # Percent Salary Hike correlacionado com Performance Rating\n",
    "    data['PercentSalaryHike'] = np.where(\n",
    "        data['PerformanceRating'] == 4,\n",
    "        np.random.randint(15, 26, n_samples),\n",
    "        np.random.randint(11, 18, n_samples)\n",
    "    )\n",
    " \n",
    "    # Stock Option Level correlacionado com JobLevel\n",
    "    data['StockOptionLevel'] = np.random.choice([0, 1, 2, 3], n_samples,\n",
    "                                               p=[0.40, 0.35, 0.20, 0.05])\n",
    "    high_level_mask = data['JobLevel'] >= 4\n",
    "    data['StockOptionLevel'][high_level_mask] = np.random.choice([1, 2, 3],\n",
    "                                                                 high_level_mask.sum(),\n",
    "                                                                 p=[0.30, 0.50, 0.20])\n",
    " \n",
    "    # Training Times Last Year\n",
    "    data['TrainingTimesLastYear'] = np.random.choice([0, 1, 2, 3, 4, 5, 6], n_samples,\n",
    "                                                    p=[0.05, 0.10, 0.25, 0.30, 0.20, 0.08, 0.02])\n",
    " \n",
    "    # Marital Status\n",
    "    data['MaritalStatus'] = np.random.choice(['Single', 'Married', 'Divorced'], n_samples,\n",
    "                                           p=[0.32, 0.55, 0.13])\n",
    " \n",
    "    # OverTime - maior probabilidade para níveis menores e pessoas mais jovens\n",
    "    overtime_base_prob = 0.28\n",
    "    age_factor = (65 - data['Age']) / 47 * 0.1  # Jovens trabalham mais overtime\n",
    "    level_factor = (5 - data['JobLevel']) / 4 * 0.1  # Níveis menores trabalham mais overtime\n",
    " \n",
    "    overtime_prob = np.clip(overtime_base_prob + age_factor + level_factor, 0.1, 0.5)\n",
    "    data['OverTime'] = [np.random.choice(['Yes', 'No'], p=[p, 1-p]) for p in overtime_prob]\n",
    " \n",
    "    # Attrition - baseado em múltiplos fatores\n",
    "    attrition_score = np.zeros(n_samples)\n",
    " \n",
    "    # Fatores que aumentam attrition\n",
    "    attrition_score += (data['JobSatisfaction'] == 1) * 0.15\n",
    "    attrition_score += (data['EnvironmentSatisfaction'] == 1) * 0.10\n",
    "    attrition_score += (data['WorkLifeBalance'] == 1) * 0.10\n",
    "    attrition_score += (np.array(data['OverTime']) == 'Yes') * 0.08\n",
    "    attrition_score += (data['YearsSinceLastPromotion'] > 5) * 0.05\n",
    "    attrition_score += (data['DistanceFromHome'] > 20) * 0.05\n",
    "    attrition_score += (np.array(data['MaritalStatus']) == 'Single') * 0.03\n",
    "    attrition_score += (data['NumCompaniesWorked'] > 5) * 0.04\n",
    " \n",
    "    # Fatores que diminuem attrition\n",
    "    attrition_score -= (data['JobLevel'] >= 4) * 0.10\n",
    "    attrition_score -= (data['YearsAtCompany'] > 10) * 0.08\n",
    "    attrition_score -= (data['StockOptionLevel'] > 0) * 0.05\n",
    " \n",
    "    # Probabilidade base de 16%\n",
    "    attrition_prob = np.clip(0.16 + attrition_score, 0.05, 0.50)\n",
    "    data['Attrition'] = [np.random.choice(['Yes', 'No'], p=[p, 1-p]) for p in attrition_prob]\n",
    " \n",
    "    # Campos fixos\n",
    "    data['EmployeeCount'] = np.ones(n_samples, dtype=int)\n",
    "    data['EmployeeNumber'] = np.arange(1, n_samples + 1)\n",
    "    data['Over18'] = ['Y'] * n_samples\n",
    "    data['StandardHours'] = [80] * n_samples\n",
    " \n",
    "    # Criar DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    " \n",
    "    # Reordenar colunas para match com o dataset original\n",
    "    column_order = [\n",
    "        'Age', 'Attrition', 'BusinessTravel', 'DailyRate', 'Department',\n",
    "        'DistanceFromHome', 'Education', 'EducationField', 'EmployeeCount',\n",
    "        'EmployeeNumber', 'EnvironmentSatisfaction', 'Gender', 'HourlyRate',\n",
    "        'JobInvolvement', 'JobLevel', 'JobRole', 'JobSatisfaction',\n",
    "        'MaritalStatus', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked',\n",
    "        'Over18', 'OverTime', 'PercentSalaryHike', 'PerformanceRating',\n",
    "        'RelationshipSatisfaction', 'StandardHours', 'StockOptionLevel',\n",
    "        'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance',\n",
    "        'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
    "        'YearsWithCurrManager'\n",
    "    ]\n",
    " \n",
    "    return df[column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b891698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_ibm_hr_dataset(n_samples=1_000_000, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d758608",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Realiza o Tratamento das colunas\n",
    "\n",
    "# Remover colunas com valores únicos\n",
    "single_value_cols = ['EmployeeCount', 'Over18', 'StandardHours']\n",
    "df = df.drop(columns=single_value_cols)\n",
    "print(f\"Colunas removidas (valor único): {single_value_cols}\")\n",
    "\n",
    "# Remover EmployeeNumber (ID único)\n",
    "df = df.drop(columns=['EmployeeNumber'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33947749",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Cria uma váriavel com os dados do dataframe original\n",
    "original_df = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a944a18",
   "metadata": {},
   "source": [
    "# 1. Análise Exploratória"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f8a589",
   "metadata": {},
   "source": [
    "###  1.1 Análise estatística completa das variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700abb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função que calcula medidas estatísticas importantes como média, mediana, desvio padrão, mínimo, máximo, frequência de valores e contagem de registros únicos.\n",
    "df.describe(include='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dad39e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifica se possui valores ausentes nas linhas do DataFrame\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c216c0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71424b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Determina todas as colunas que são variaveis númericas\n",
    "cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "#Gera visões das variaveis categóricas em quantidade\n",
    "for col in cat_cols:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    ax = sns.countplot(x=col, data=df, order=df[col].value_counts().index)\n",
    "    plt.title(f'Distribuição da variável: {col}', fontsize=14)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Contagem')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Adiciona rótulos de contagem acima das barras\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        ax.annotate(f'{height}', (p.get_x() + p.get_width() / 2, height),\n",
    "                    ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd12e45",
   "metadata": {},
   "source": [
    "#### Curva galciana pesquisar a relação se é possível aplicar ela ou outra método matematico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44751d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determina todas as colunas que são variaveis númericas\n",
    "num_cols = df.select_dtypes(include=['int32', 'float32']).columns\n",
    "\n",
    "#Gera visões das variaveis númericas em quantidade\n",
    "for col in num_cols:\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    # Histograma com KDE\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(df[col], kde=True)\n",
    "    plt.title(f'Distribuição - {col}')\n",
    "\n",
    "    # Boxplot para detectar outliers\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f'Outliers - {col}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe54141",
   "metadata": {},
   "source": [
    "### Correlação | Valor absoluto (|r|) | Força |  |\n",
    "#### |------------------|------------------|------------------|----------------------------------|\n",
    "#### | ±0.00 a ±0.30 | fraca ou nula | Fraca | Pode manter ambas |\n",
    "#### | ±0.30 a ±0.70 | moderada | Moderada | Avaliar caso a caso |\n",
    "#### | ±0.75 a ±1.00 | forte | Muito forte | Evitar usar juntas no modelo |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978e27c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcula a correlação entre todas as variáveis numéricas, gerando uma matriz que mostra como elas se relacionam entre si (de -1 a +1).\n",
    "correlation_matrix = df[num_cols].corr()\n",
    "#Identifica a correlação das variaveis númericas\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Matriz de Correlação entre Variáveis Numéricas')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2066e03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Atritos das váriaveis categóricas\n",
    "for col in cat_cols:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    ax = sns.countplot(x=col, hue='Attrition', data=df, order=df[col].value_counts().index)\n",
    "    plt.title(f'Attrition por {col}')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Adiciona os valores no topo de cada barra\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        if height > 0:\n",
    "            ax.annotate(f'{height}', \n",
    "                        (p.get_x() + p.get_width() / 2., height), \n",
    "                        ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65559cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para variáveis categóricas com tamanhos diferentes entre os grupos, sempre use proporção (taxa) em vez de quantidade absoluta\n",
    "#para analisar o attrition.\n",
    "\n",
    "\n",
    "for cat_col in cat_cols:\n",
    "    # Calcula a taxa de Attrition por categoria\n",
    "    attrition_rate = pd.crosstab(df[cat_col], df['Attrition'], normalize='index') * 100\n",
    "\n",
    "    # Ordena pela taxa 'Yes' (quem saiu)\n",
    "    attrition_rate = attrition_rate.sort_values(by='Yes', ascending=False)\n",
    "\n",
    "    # Plota o gráfico\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    ax = sns.barplot(x=attrition_rate.index, y=attrition_rate['Yes'], color='orange')\n",
    "\n",
    "    # Adiciona os rótulos nas barras\n",
    "    for i, v in enumerate(attrition_rate['Yes']):\n",
    "        ax.text(i, v + 0.3, f'{v:.1f}%', ha='center', fontweight='bold')\n",
    "\n",
    "    plt.ylim(0, attrition_rate['Yes'].max() + 5)\n",
    "    plt.title(f'Taxa de Attrition por {cat_col}')\n",
    "    plt.ylabel('Attrition (%)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463da7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Atritos das váriaveis númericas\n",
    "for col in num_cols:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(x='Attrition', y=col, data=df)\n",
    "    plt.title(f'{col} por Attrition')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202c738b",
   "metadata": {},
   "source": [
    "###  Insights de negócio relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f385b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Insights - Overtime(Horas Extras)\n",
    "#Interpretação:\n",
    "#Funcionários que fazem hora extra apresentam mais chances de sair da empresa. \n",
    "\n",
    "cat_col = 'OverTime'\n",
    "\n",
    "# Tabela de proporções\n",
    "attrition_rate = pd.crosstab(df[cat_col], df['Attrition'], normalize='index') * 100\n",
    "\n",
    "# Ordena do maior para o menor\n",
    "attrition_rate = attrition_rate.sort_values(by='Yes', ascending=False)\n",
    "\n",
    "# Criação do gráfico\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.barplot(x=attrition_rate.index, y=attrition_rate['Yes'], color='orange')\n",
    "\n",
    "# Adiciona valores nas barras\n",
    "for i, v in enumerate(attrition_rate['Yes']):\n",
    "    ax.text(i, v + 0.3, f'{v:.1f}%', ha='center', fontweight='bold')\n",
    "\n",
    "plt.ylim(0, attrition_rate['Yes'].max() + 5)  # melhora o espaço\n",
    "plt.ylabel('Taxa de Attrition (%)')\n",
    "plt.title(f'Taxa de Attrition por {cat_col}')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0bea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Insights - Salário por Mês baseado no Atrition\n",
    "#Interpretação:\n",
    "#Se a caixa de Attrition = Yes estiver mais baixa, indica que pessoas com menor salário saem mais.\n",
    "\n",
    "#Diferenças entre medianas também são um sinal claro.\n",
    "\n",
    "#Outliers podem indicar exceções (ex: salários muito altos que também pediram demissão).\n",
    "\n",
    "\n",
    "sns.boxplot(x='Attrition', y='MonthlyIncome', data=df)\n",
    "plt.title('MonthlyIncome por Attrition')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a2df23",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Insights - MaritalStatus(Estado Cível)\n",
    "#interpretação:\n",
    "#Funcionários solteiros apresentam maior propensão ao desligamento.\n",
    "#Isso pode estar ligado a maior mobilidade, menor comprometimento com estabilidade ou busca por novas oportunidades.\n",
    "\n",
    "cat_col = 'MaritalStatus'\n",
    "\n",
    "# Tabela de proporções\n",
    "attrition_rate = pd.crosstab(df[cat_col], df['Attrition'], normalize='index') * 100\n",
    "\n",
    "# Ordena do maior para o menor\n",
    "attrition_rate = attrition_rate.sort_values(by='Yes', ascending=False)\n",
    "\n",
    "# Criação do gráfico\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.barplot(x=attrition_rate.index, y=attrition_rate['Yes'], color='orange')\n",
    "\n",
    "# Adiciona valores nas barras\n",
    "for i, v in enumerate(attrition_rate['Yes']):\n",
    "    ax.text(i, v + 0.3, f'{v:.1f}%', ha='center', fontweight='bold')\n",
    "\n",
    "plt.ylim(0, attrition_rate['Yes'].max() + 5)  # melhora o espaço\n",
    "plt.ylabel('Taxa de Attrition (%)')\n",
    "plt.title(f'Taxa de Attrition por {cat_col}')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7243cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Insights - JobRole(Cargo)\n",
    "#Interpretaçaõ:\n",
    "#Não há grande variação de attrition entre os cargos, porém se destaca o cargo de Research Scientist\n",
    "cat_col = 'JobRole'\n",
    "\n",
    "# Tabela de proporções\n",
    "attrition_rate = pd.crosstab(df[cat_col], df['Attrition'], normalize='index') * 100\n",
    "\n",
    "# Ordena do maior para o menor\n",
    "attrition_rate = attrition_rate.sort_values(by='Yes', ascending=False)\n",
    "\n",
    "# Criação do gráfico\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.barplot(x=attrition_rate.index, y=attrition_rate['Yes'], color='orange')\n",
    "\n",
    "# Adiciona valores nas barras\n",
    "for i, v in enumerate(attrition_rate['Yes']):\n",
    "    ax.text(i, v + 0.3, f'{v:.1f}%', ha='center', fontweight='bold')\n",
    "\n",
    "plt.ylim(0, attrition_rate['Yes'].max() + 5)  # melhora o espaço\n",
    "plt.ylabel('Taxa de Attrition (%)')\n",
    "plt.title(f'Taxa de Attrition por {cat_col}')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d3bcc9",
   "metadata": {},
   "source": [
    "# 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b8f199",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature - Tempo com gerente em relação ao tempo total\n",
    "df['RatioWithManager'] = df['YearsWithCurrManager'] / (df['YearsAtCompany'] + 1)  # +1 para evitar divisão por zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c0d687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpretação:\n",
    "\n",
    "#Valor da RatioWithManager\tSignificado\n",
    "#Perto de 1.0\tEstá com o mesmo gerente desde que entrou na empresa\n",
    "#Perto de 0.0\tEstá há pouco tempo com o gerente (pode ser instável)\n",
    "#Médio (0.4 ~ 0.7)\tGerente mudou no meio do caminho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20a17c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='Attrition', y='RatioWithManager', data=df)\n",
    "plt.title('Attrition x Tempo com o mesmo gerente')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac94da7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a37821",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Feature - Faixa da Renda\n",
    "#Interpretação:\n",
    "#O gráfico mostra que funcionários de baixa renda (1) têm uma maior taxa de saída (attrition) do que os de alta renda (0).\n",
    "#20,4% dos funcionários de baixa renda saíram da empresa\n",
    "#Contra 15,4% dos de alta renda\n",
    "\n",
    "# Definir um limiar de baixa renda (ex: abaixo da mediana)\n",
    "income_threshold = df['MonthlyIncome'].median()\n",
    "\n",
    "# Criar a feature binária\n",
    "df['LowIncomeFlag'] = (df['MonthlyIncome'] < income_threshold).astype(int)\n",
    "\n",
    "# Calcular proporção de attrition por faixa de renda\n",
    "attrition_rate = pd.crosstab(df['LowIncomeFlag'], df['Attrition'], normalize='index') * 100\n",
    "\n",
    "# Organizar visualmente\n",
    "plt.figure(figsize=(7, 5))\n",
    "ax = sns.barplot(\n",
    "    x=attrition_rate.index,\n",
    "    y=attrition_rate['Yes'],\n",
    "    palette='Set2'\n",
    ")\n",
    "\n",
    "# Adicionar rótulos nas barras\n",
    "for i, v in enumerate(attrition_rate['Yes']):\n",
    "    ax.text(i, v + 1, f'{v:.1f}%', ha='center', fontweight='bold')\n",
    "\n",
    "# Títulos e rótulos\n",
    "plt.title('Attrition por Faixa de Renda', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Faixa de Renda (0 = Alta Renda, 1 = Baixa Renda)', fontsize=12)\n",
    "plt.ylabel('Attrition (%)', fontsize=12)\n",
    "plt.ylim(0, attrition_rate['Yes'].max() + 10)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4ced6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Feature - MaritalStatus(Estado Cível)\n",
    "#interpretação:\n",
    "#Funcionários solteiros apresentam maior propensão ao desligamento.\n",
    "#Isso pode estar ligado a maior mobilidade, menor comprometimento com estabilidade ou busca por novas oportunidades.\n",
    "\n",
    "df['IsSingle'] = (df['MaritalStatus'] == 'Single').astype(int)\n",
    "\n",
    "# Tabela de proporções\n",
    "attrition_rate = pd.crosstab(df['IsSingle'], df['Attrition'], normalize='index') * 100\n",
    "\n",
    "# Ordena do maior para o menor\n",
    "attrition_rate = attrition_rate.sort_values(by='Yes', ascending=False)\n",
    "#Grafico\n",
    "plt.figure(figsize=(6, 5))\n",
    "ax = sns.barplot(\n",
    "    x=attrition_rate.index.map({0: 'Casado/Divorciado', 1: 'Solteiro'}), \n",
    "    y=attrition_rate['Yes'], \n",
    "    palette='Oranges'\n",
    ")\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for i, v in enumerate(attrition_rate['Yes']):\n",
    "    ax.text(i, v + 1, f'{v:.1f}%', ha='center', fontweight='bold')\n",
    "\n",
    "# Estilização\n",
    "plt.ylim(0, attrition_rate['Yes'].max() + 10)\n",
    "plt.title('Attrition por Estado Civil', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Estado Civil', fontsize=12)\n",
    "plt.ylabel('Attrition (%)', fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835c7993",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Feature - Overtime(Horas Extras)\n",
    "#Interpretação:\n",
    "#Funcionários que fazem hora extra apresentam mais chances de sair da empresa. \n",
    "df['OverTimeFlag'] = (df['OverTime'] == 'Yes').astype(int)\n",
    "\n",
    "# Preparar dados para visualização\n",
    "df_plot = df.replace({'Attrition': {'Yes': 1, 'No': 0}})\n",
    "attrition_by_overtime = df_plot.groupby('OverTimeFlag')['Attrition'].mean().reset_index()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = sns.barplot(x='OverTimeFlag', y='Attrition', data=attrition_by_overtime, color='orange')\n",
    "\n",
    "# Adicionar os rótulos de porcentagem\n",
    "for i, v in enumerate(attrition_by_overtime['Attrition']):\n",
    "    ax.text(i, v + 0.01, f'{v:.1%}', ha='center', fontweight='bold')\n",
    "\n",
    "# Personalização\n",
    "plt.title('Attrition por OverTimeFlag')\n",
    "plt.ylabel('Proporção de Attrition')\n",
    "plt.xlabel('OverTimeFlag (0 = Não, 1 = Sim)')\n",
    "plt.ylim(0, attrition_by_overtime['Attrition'].max() + 0.1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa9e0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Feature - JobRole(Cargo)\n",
    "#Interpretaçaõ:\n",
    "#Não há grande variação de attrition entre os cargos, porém se destaca o cargo de Research Scientist\n",
    "df['IsResearchScientist'] = (df['JobRole'] == 'Research Scientist').astype(int)\n",
    "\n",
    "# Calcular proporções de attrition por grupo\n",
    "attrition_rate = pd.crosstab(df['IsResearchScientist'], df['Attrition'], normalize='index') * 100\n",
    "\n",
    "# Plotar\n",
    "plt.figure(figsize=(6, 5))\n",
    "ax = sns.barplot(x=attrition_rate.index, y=attrition_rate['Yes'], palette='Set2')\n",
    "\n",
    "# Adicionar rótulos nas barras\n",
    "for i, v in enumerate(attrition_rate['Yes']):\n",
    "    ax.text(i, v + 0.5, f'{v:.1f}%', ha='center', fontweight='bold')\n",
    "\n",
    "# Ajustes de rótulo e layout\n",
    "plt.title('Attrition por Cargo Research Scientist', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('É Research Scientist? (0 = Não, 1 = Sim)', fontsize=12)\n",
    "plt.ylabel('Attrition (%)', fontsize=12)\n",
    "plt.ylim(0, attrition_rate['Yes'].max() + 10)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9881ad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Feature - Satisfação total das variaveis ambiente, relacionamento, equilíbrio vida-trabalho e satisfação com o cargo \n",
    "df['SatisfactionIndex'] = (\n",
    "    df['JobSatisfaction'] +\n",
    "    df['EnvironmentSatisfaction'] +\n",
    "    df['RelationshipSatisfaction'] +\n",
    "    df['WorkLifeBalance']\n",
    ") / 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b256e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpretação:\n",
    "#Funcionários com menor índice de satisfação geral apresentam maior propensão a sair da empresa.\n",
    "#Isso indica que fatores como ambiente, relacionamento, equilíbrio vida-trabalho e satisfação com \n",
    "#o cargo impactam diretamente a retenção.\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(x='Attrition', y='SatisfactionIndex', data=df)\n",
    "plt.title('SatisfactionIndex por Attrition')\n",
    "plt.ylabel('Índice de Satisfação')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd2cd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Possível Feature -Risco de Burnout\n",
    "df['BurnoutRisk'] = ((df['OverTime'] == 'Yes') & (df['SatisfactionIndex'] < 3)).astype(int)\n",
    "\n",
    "#A coluna BurnoutRisk foi definida como:\n",
    "#1 (Sim) → Funcionários que fazem hora extra (OverTime == 'Yes') e possuem baixo índice de satisfação (SatisfactionIndex < 3)\n",
    "#0 (Não) → Todos os demais funcionário\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2513faa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpretação:\n",
    "\n",
    "#Funcionários que apresentam sinais de risco de burnout \n",
    "#(ou seja, trabalham em regime de hora extra e estão insatisfeitos) \n",
    "#possuem uma taxa de saída significativamente mais alta:\n",
    "#25,6% contra 16,1%.\n",
    "\n",
    "\n",
    "# Cria gráfico de taxa de attrition para a variável binária BurnoutRisk\n",
    "attrition_rate = pd.crosstab(df['BurnoutRisk'], df['Attrition'], normalize='index') * 100\n",
    "attrition_rate = attrition_rate.sort_values(by='Yes', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = sns.barplot(x=attrition_rate.index.astype(str), y=attrition_rate['Yes'], color='orange')\n",
    "\n",
    "# Adiciona rótulos\n",
    "for i, v in enumerate(attrition_rate['Yes']):\n",
    "    ax.text(i, v + 0.5, f'{v:.1f}%', ha='center', fontweight='bold')\n",
    "\n",
    "plt.ylabel('Attrition (%)')\n",
    "plt.xlabel('Risco de Burnout (0 = Não, 1 = Sim)')\n",
    "plt.title('Taxa de Attrition por BurnoutRisk')\n",
    "plt.ylim(0, attrition_rate['Yes'].max() + 5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb6d6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature - Grupo por idade\n",
    "df['AgeGroup'] = pd.cut(df['Age'],bins=[16, 30, 45, 60, 100],labels=['Jovem', 'Adulto', 'Meia-idade', 'Senhor'], include_lowest=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117b064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Interpretação:\n",
    "#Jovens têm maior tendência a sair da empresa: Com uma taxa de 21,3%, é o grupo com maior atrito. \n",
    "#Pode indicar instabilidade, busca por crescimento rápido ou insatisfação.\n",
    "\n",
    "\n",
    "# Cálculo da taxa de Attrition por faixa etária\n",
    "attrition_rate = pd.crosstab(df['AgeGroup'], df['Attrition'], normalize='index') * 100\n",
    "attrition_rate = attrition_rate.sort_values(by='Yes', ascending=False)\n",
    "\n",
    "# Gráfico\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.barplot(x=attrition_rate.index, y=attrition_rate['Yes'], color='orange')\n",
    "\n",
    "# Adiciona os rótulos de porcentagem nas barras\n",
    "for i, v in enumerate(attrition_rate['Yes']):\n",
    "    ax.text(i, v + 0.5, f'{v:.1f}%', ha='center', fontweight='bold')\n",
    "\n",
    "plt.title('Taxa de Attrition por Grupo de Idade')\n",
    "plt.ylabel('Attrition (%)')\n",
    "plt.xlabel('Grupo de Idade')\n",
    "plt.ylim(0, attrition_rate['Yes'].max() + 5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd3b8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature - Relação entre tempo na empresa e tempo total de trabalho.\n",
    "df['TenureRatio'] = df['YearsAtCompany'] / df['TotalWorkingYears'].replace(0, np.nan)\n",
    "# Remover valores NaN resultantes de divisão por 0 (se houver)\n",
    "#df = df.dropna(subset=['TenureRatio'])\n",
    "df['TenureRatio'] = df['TenureRatio'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d38de7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpretação:\n",
    "#Quanto menor o tempo relativo de carreira na empresa, maior o risco de saída.\n",
    "\n",
    "# Agrupando a variável em faixas para visualização\n",
    "df['TenureRatioGroup'] = pd.cut(df['TenureRatio'], \n",
    "                                bins=[0, 0.25, 0.5, 0.75, 1.0],\n",
    "                                labels=['Baixo', 'Médio', 'Alto', 'Muito Alto'])\n",
    "\n",
    "# Calculando a taxa de attrition por grupo\n",
    "attrition_rate = pd.crosstab(df['TenureRatioGroup'], df['Attrition'], normalize='index') * 100\n",
    "attrition_rate = attrition_rate.sort_values(by='Yes', ascending=False)\n",
    "\n",
    "# Ordena os grupos na ordem original de faixas\n",
    "order = ['Baixo', 'Médio', 'Alto', 'Muito Alto']\n",
    "\n",
    "# Gráfico corrigido\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.barplot(x=attrition_rate.index, y=attrition_rate['Yes'], color='orange', order=order)\n",
    "\n",
    "# Adiciona os rótulos nas barras\n",
    "for i, v in enumerate(attrition_rate.loc[order]['Yes']):\n",
    "    ax.text(i, v + 0.5, f'{v:.1f}%', ha='center', fontweight='bold')\n",
    "\n",
    "plt.ylabel('Attrition (%)')\n",
    "plt.xlabel('Proporção do Tempo de Carreira na Empresa')\n",
    "plt.title('Attrition por TenureRatio')\n",
    "plt.ylim(0, attrition_rate['Yes'].max() + 5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6a3f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Feature - Stock Options(Beneficios corporativo)\n",
    "#Valor\tSignificado\n",
    "#Nenhum\tNenhuma opção de de beneficio\n",
    "#Baixo\tNível básico de stock option\n",
    "#2 e 3\tNível médio e alto\n",
    "df['StockOptionCategory'] = pd.cut(df['StockOptionLevel'],bins=[-1, 0, 1, 3],  labels=['Nenhum', 'Baixo', 'Alto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d359884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Interprete:\n",
    "#A oferta de stock options parece ter efeito direto na retenção:\n",
    "#Funcionários com benefícios de longo prazo (como ações da empresa) tendem a permanecer mais tempo.\n",
    "#Isso sugere que ações são um fator importante de engajamento.\n",
    "\n",
    "\n",
    "# Calcula a tabela de proporções\n",
    "attrition_crosstab = pd.crosstab(df['StockOptionCategory'], df['Attrition'], normalize='index') * 100\n",
    "\n",
    "# Cria o gráfico\n",
    "ax = attrition_crosstab.plot(\n",
    "    kind='bar',\n",
    "    stacked=True,\n",
    "    color=['gray', 'orange'],\n",
    "    figsize=(8, 5)\n",
    ")\n",
    "\n",
    "# Adiciona os rótulos de porcentagem em cada segmento\n",
    "for i, (idx, row) in enumerate(attrition_crosstab.iterrows()):\n",
    "    bottom = 0\n",
    "    for attrition_status in ['No', 'Yes']:\n",
    "        value = row[attrition_status]\n",
    "        if value > 0:\n",
    "            ax.text(i, bottom + value / 2, f'{value:.1f}%', ha='center', va='center', fontsize=9, color='white', fontweight='bold')\n",
    "        bottom += value\n",
    "\n",
    "# Ajustes do gráfico\n",
    "plt.title('Distribuição de Attrition por Nível de Stock Option')\n",
    "plt.ylabel('Proporção (%)')\n",
    "plt.xlabel('Stock Option Level')\n",
    "plt.legend(title='Attrition')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b94dcb",
   "metadata": {},
   "source": [
    "### Polynomial feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60578c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polynomial feature - Baseado nas colunas Age, MonthlyIncome e Tuneratio\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(df[['Age', 'MonthlyIncome', 'TenureRatio']])\n",
    "feature_names = poly.get_feature_names_out(['Age', 'MonthlyIncome', 'TenureRatio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b827db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00410b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly_df = pd.DataFrame(X_poly, columns=feature_names)\n",
    "X_poly_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3de4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interprete:\n",
    "#| Feature                       | Correlação com Attrition | Interpretação Rápida                     |\n",
    "#| ----------------------------- | ------------------------ | ---------------------------------------- |\n",
    "#| `TenureRatio`                 | **+0.0025**              | Quase nenhuma correlação com atrito.     |\n",
    "#| `TenureRatio^2`               | **+0.0021**              | Correlação ainda muito fraca.            |\n",
    "#| `MonthlyIncome * TenureRatio` | **+0.0020**              | Quase nula também.                       |\n",
    "#| `Age * TenureRatio`           | **+0.0019**              | Muito fraca.                             |\n",
    "#| `MonthlyIncome^2`             | **+0.0015**              | Sem impacto relevante.                   |\n",
    "#| `Age^2`                       | **-0.0015**              | Inversamente muito pouco correlacionada. |\n",
    "#| `Age * MonthlyIncome`         | **-0.0016**              | Quase nada.                              |\n",
    "#| `MonthlyIncome`               | **-0.0017**              | Quase nada.                              |\n",
    "\n",
    "X_poly_df['Attrition'] = df['Attrition'].map({'No': 0, 'Yes': 1})\n",
    "X_poly_df.corr()['Attrition'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453c4c5a",
   "metadata": {},
   "source": [
    "####  Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe373d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "df['AgeGroup_encoded'] = encoder.fit_transform(df[['AgeGroup']]).astype(int)\n",
    "\n",
    "# Descobrir quantas categorias únicas foram codificadas\n",
    "n_categories = df['AgeGroup_encoded'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bed586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrada\n",
    "age_input = Input(shape=(1,))\n",
    "age_embedding = Embedding(input_dim=n_categories, output_dim=2)(age_input)\n",
    "age_vector = Flatten()(age_embedding)\n",
    "\n",
    "# Saída\n",
    "output = Dense(1, activation='sigmoid')(age_vector)\n",
    "model = Model(inputs=age_input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2e40a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilação\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df903832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste: garantir que X esteja no formato certo (array ou Series com shape=(n,1))\n",
    "X_age = df['AgeGroup_encoded'].values.reshape(-1, 1)\n",
    "y = df['Attrition'].apply(lambda x: 1 if x == 'Yes' else 0)  # se necessário\n",
    "\n",
    "# Treinamento\n",
    "model.fit(X_age, y, epochs=10, batch_size=32)\n",
    "\n",
    "# Embedding aplicado à variável categórica AgeGroup\n",
    "# A rede neural simples foi treinada para mapear cada grupo etário ('Jovem', 'Adulto', etc.)\n",
    "# em um vetor denso (2D), otimizando para prever a variável alvo Attrition (0 ou 1).\n",
    "# O modelo alcançou ~82% de acurácia usando apenas AgeGroup como entrada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d5684e",
   "metadata": {},
   "source": [
    "### Bloco de separação dos modelos X, Y e Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6896d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar features e target\n",
    "X = original_df.drop('Attrition', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eead3f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar features e target\n",
    "Y = original_df['Attrition'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3316b00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acrescentar as features em um DataFrame especifico\n",
    "X_eng = X.copy()\n",
    "#Feature 1\n",
    "X_eng['RatioWithManager'] = X_eng['YearsWithCurrManager'] / (X_eng['YearsAtCompany'] + 1) \n",
    "#Feature 2\n",
    "X_eng['SatisfactionIndex'] = ( X_eng['JobSatisfaction'] + X_eng['EnvironmentSatisfaction'] + X_eng['RelationshipSatisfaction'] + X_eng['WorkLifeBalance'] ) / 4\n",
    "#Feature 3\n",
    "X_eng['BurnoutRisk'] = ((X_eng['OverTime'] == 'Yes') & (X_eng['SatisfactionIndex'] < 3)).astype(int)\n",
    "#Feature 4\n",
    "X_eng['AgeGroup'] = pd.cut(X_eng['Age'],bins=[16, 30, 45, 60, 100],labels=['Jovem', 'Adulto', 'Meia-idade', 'Senhor'],include_lowest=True\n",
    ")\n",
    "#Feature 5\n",
    "X_eng['TenureRatio'] = X_eng['YearsAtCompany'] / X_eng['TotalWorkingYears'].replace(0, np.nan)\n",
    "X_eng['TenureRatio'] = X_eng['TenureRatio'].fillna(0)\n",
    "#Feature 6\n",
    "X_eng['StockOptionCategory'] = pd.cut(X_eng['StockOptionLevel'],bins=[-1, 0, 1, 3],  labels=['Nenhum', 'Baixo', 'Alto'])\n",
    "#Feature 7\n",
    "X_eng['OverTimeFlag'] = (X_eng['OverTime'] == 'Yes').astype(int)\n",
    "#Feature 8\n",
    "income_threshold = X_eng['MonthlyIncome'].median()\n",
    "X_eng['LowIncomeFlag'] = (X_eng['MonthlyIncome'] < income_threshold).astype(int)\n",
    "#Feature 9\n",
    "X_eng['IsSingle'] = (X_eng['MaritalStatus'] == 'Single').astype(int)\n",
    "#Feature 10\n",
    "X_eng['IsResearchScientist'] = (X_eng['JobRole'] == 'Research Scientist').astype(int)\n",
    "\n",
    "\n",
    "#Feature 11- Acrescentar as features de Técnicas Avançadas - Polynomial features\n",
    "# 1. Gerar as polynomial features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(X_eng[['Age', 'MonthlyIncome', 'TenureRatio']])\n",
    "\n",
    "# 2. Pegar os nomes das novas features\n",
    "feature_names = poly.get_feature_names_out(['Age', 'MonthlyIncome', 'TenureRatio'])\n",
    "\n",
    "# 3. Criar um DataFrame com as polynomial features\n",
    "df_poly = pd.DataFrame(X_poly, columns=feature_names, index=X_eng.index)\n",
    "\n",
    "# 4. Concatenar com o seu DataFrame X_eng\n",
    "X_eng = pd.concat([X_eng, df_poly], axis=1)\n",
    "\n",
    "#Feature 12 - Acrescentar as features de Técnicas Avançadas - Embeddings\n",
    "\n",
    "# 1. Codificar AgeGroup\n",
    "encoder = OrdinalEncoder()\n",
    "X_eng['AgeGroup_encoded'] = encoder.fit_transform(X_eng[['AgeGroup']]).astype(int)\n",
    "\n",
    "# 2. Criar modelo para treinar embedding (input_dim = nº de categorias)\n",
    "input_dim = X_eng['AgeGroup_encoded'].nunique()\n",
    "embedding_dim = 2\n",
    "\n",
    "# Definir entrada e embedding\n",
    "age_input = Input(shape=(1,))\n",
    "age_embedding = Embedding(input_dim=input_dim, output_dim=embedding_dim, input_length=1)(age_input)\n",
    "age_vector = Flatten()(age_embedding)\n",
    "\n",
    "# Modelo apenas para gerar o vetor denso (não é um modelo final preditivo)\n",
    "embedding_model = Model(inputs=age_input, outputs=age_vector)\n",
    "\n",
    "# 3. Gerar o vetor de embedding para todos os registros\n",
    "age_embeddings = embedding_model.predict(X_eng[['AgeGroup_encoded']])\n",
    "\n",
    "# 4. Adicionar os vetores ao DataFrame\n",
    "for i in range(embedding_dim):\n",
    "    X_eng[f'AgeGroup_emb_{i}'] = age_embeddings[:, i]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5608fbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove colunas duplicadas de forma mais eficiente\n",
    "X_eng = X_eng.loc[:, ~X_eng.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ba9152",
   "metadata": {},
   "source": [
    "##  Modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b5e0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X: dataframe de features com engenharia,polynomias e embeddings\n",
    "# y: variável target binária\n",
    "x_treino = X_eng.copy()\n",
    "y_treino = original_df['Attrition'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4a8315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Separar colunas por tipo\n",
    "numeric_features  = X_eng.select_dtypes(include=['int64', 'float64', 'int32', 'float32']).columns.tolist()\n",
    "categorical_features = X_eng.select_dtypes(include=['object', 'category']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Transformadores\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(drop='first', sparse_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecd887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Pré-processador combinado\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb905f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Pipeline com modelo\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_jobs=-1, verbose=1, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e75b242",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 6. Separar treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_treino, y_treino, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42dc8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# Treinamento e Avaliação de Múltiplos Modelos de ML\n",
    "# ========================================================\n",
    "# Este bloco implementa o pipeline completo para testar,\n",
    "# ajustar e avaliar diferentes algoritmos de classificação\n",
    "# com foco em predição de rotatividade de funcionários.\n",
    "\n",
    "# 🔹 Modelos utilizados:\n",
    "# - Random Forest\n",
    "# - Logistic Regression\n",
    "# - CatBoost\n",
    "# - LightGBM\n",
    "# - Voting Ensemble (combinação dos 4 modelos acima)\n",
    "\n",
    "# 🔹 Etapas executadas:\n",
    "# 1. Criação de dicionário com os modelos\n",
    "# 2. Definição de grades de hiperparâmetros para otimização\n",
    "# 3. Treinamento com validação cruzada (GridSearchCV para os modelos com hiperparâmetros)\n",
    "# 4. Avaliação dos modelos com threshold ajustado (0.3)\n",
    "# 5. Geração de métricas específicas: F1, F2, Balanced Accuracy, MCC, PR-AUC\n",
    "# 6. Visualização:\n",
    "#    - Matriz de confusão\n",
    "#    - Curva Precision-Recall\n",
    "#    - Gráfico de importância das variáveis (quando aplicável)\n",
    "# 7. Avaliação de viés (fairness) por subgrupos (ex: gênero, cargo, departamento)\n",
    "# 8. Armazenamento do modelo final (Voting Ensemble) em .pkl\n",
    "# 9. Geração de tabela comparativa final com todas as métricas para análise\n",
    "\n",
    "# 📝 Objetivo:\n",
    "# Selecionar o melhor modelo para prever a saída de funcionários,\n",
    "# garantindo alta sensibilidade (recall) e interpretabilidade,\n",
    "# mesmo diante de um conjunto de dados desbalanceado.\n",
    "\n",
    "# Modelos individuais + ensemble\n",
    "modelos = {\n",
    "    'Random Forest': RandomForestClassifier(n_jobs=-1, random_state=42, class_weight='balanced'),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, class_weight='balanced'),\n",
    "    'CatBoost': CatBoostClassifier(verbose=0, auto_class_weights='Balanced'),\n",
    "    'LightGBM': LGBMClassifier(n_jobs=-1, random_state=42, class_weight='balanced'),\n",
    "    'Voting Ensemble': VotingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', RandomForestClassifier(n_jobs=-1, random_state=42, class_weight='balanced')),\n",
    "            ('lr', LogisticRegression(max_iter=1000, class_weight='balanced')),\n",
    "            ('lgbm', LGBMClassifier(n_jobs=-1, random_state=42, class_weight='balanced')),\n",
    "            ('cat', CatBoostClassifier(verbose=0, auto_class_weights='Balanced'))\n",
    "        ],\n",
    "        voting='soft',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "# Modelos com hiperparâmetros\n",
    "param_grids = {\n",
    "    'Random Forest': {\n",
    "        'classifier__n_estimators': [100, 200],\n",
    "        'classifier__max_depth': [None, 10],\n",
    "        'classifier__min_samples_split': [2, 5],\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'classifier__C': [0.01, 0.1, 1, 10],\n",
    "        'classifier__penalty': ['l2'],\n",
    "        'classifier__solver': ['lbfgs']\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'classifier__depth': [4, 6],\n",
    "        'classifier__learning_rate': [0.01, 0.1],\n",
    "        'classifier__iterations': [100]\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'classifier__n_estimators': [100, 200],\n",
    "        'classifier__max_depth': [-1, 10],\n",
    "        'classifier__learning_rate': [0.01, 0.1]\n",
    "    }\n",
    "}\n",
    "modelos_com_parametros = list(param_grids.keys())\n",
    "\n",
    "def avaliar_fairness(df, grupo_coluna, y_true, y_pred):\n",
    "    print(f\"\\n🎯 Fairness por: {grupo_coluna}\")\n",
    "    grupos = df[grupo_coluna].dropna().unique()\n",
    "    for grupo in grupos:\n",
    "        idx = df[grupo_coluna] == grupo\n",
    "        if sum(idx) == 0:\n",
    "            continue\n",
    "        recall = recall_score(y_true[idx], y_pred[idx], zero_division=0)\n",
    "        precision = precision_score(y_true[idx], y_pred[idx], zero_division=0)\n",
    "        print(f\"{grupo}: Recall = {recall:.3f}, Precision = {precision:.3f}\")\n",
    "\n",
    "\n",
    "# Resultados\n",
    "resultados = []\n",
    "\n",
    "for nome, modelo in modelos.items():\n",
    "    print(f\"\\n🔍 Treinando modelo: {nome}\")\n",
    "    \n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', modelo)\n",
    "    ])\n",
    "\n",
    "    if nome in modelos_com_parametros:\n",
    "        grid = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid=param_grids[nome],\n",
    "            cv=3,\n",
    "            scoring='f1',\n",
    "            n_jobs=4,\n",
    "            verbose=1\n",
    "        )\n",
    "        grid.fit(X_train, y_train)\n",
    "        best_model = grid.best_estimator_\n",
    "        melhores_params = grid.best_params_\n",
    "    else:\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        best_model = pipeline\n",
    "        melhores_params = \"Não aplicável\"\n",
    "\n",
    "    # Avaliação com threshold\n",
    "    y_scores = best_model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = (y_scores >= 0.3).astype(int)\n",
    "\n",
    "    print(\"\\n📋 Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=[\"Ficou\", \"Saiu\"]))\n",
    "    \n",
    "    # 🔷 Matriz de confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Ficou\", \"Saiu\"])\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    disp.plot(cmap='Blues', values_format='d')\n",
    "    plt.title(f'Matriz de Confusão: {nome}')\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    # Métricas específicas\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    f2 = fbeta_score(y_test, y_pred, beta=2)\n",
    "    bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    pr_auc = average_precision_score(y_test, y_scores)\n",
    "\n",
    "    print(\"\\n📊 Métricas específicas:\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"F2-Score: {f2:.4f}\")\n",
    "    print(f\"Balanced Accuracy: {bal_acc:.4f}\")\n",
    "    print(f\"MCC: {mcc:.4f}\")\n",
    "    print(f\"Precision-Recall AUC: {pr_auc:.4f}\")\n",
    "\n",
    "    # Curva PR\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_scores)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(recall_vals, precision_vals, marker='.')\n",
    "    plt.title(f'Precision-Recall Curve: {nome}')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # 🔎 Importância das variáveis por modelo\n",
    "    try:\n",
    "        feature_names = best_model.named_steps['preprocessing'].get_feature_names_out()\n",
    "\n",
    "        if hasattr(best_model.named_steps['classifier'], 'feature_importances_'):\n",
    "            importances = best_model.named_steps['classifier'].feature_importances_\n",
    "\n",
    "        elif nome == 'CatBoost':\n",
    "            importances = best_model.named_steps['classifier'].get_feature_importance()\n",
    "\n",
    "        elif hasattr(best_model.named_steps['classifier'], 'coef_'):\n",
    "            importances = np.abs(best_model.named_steps['classifier'].coef_).flatten()\n",
    "\n",
    "        else:\n",
    "            importances = None\n",
    "\n",
    "        if importances is not None:\n",
    "            top_idx = importances.argsort()[-15:]\n",
    "            top_features = feature_names[top_idx]\n",
    "            top_importances = importances[top_idx]\n",
    "\n",
    "            plt.figure(figsize=(6, 5))\n",
    "            plt.barh(top_features, top_importances, color='skyblue')\n",
    "            plt.title(f'Top 15 Features - {nome}')\n",
    "            plt.xlabel('Importância')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Não foi possível calcular importâncias para o modelo {nome}: {e}\")\n",
    "        \n",
    "     # 🔍 Análise de viés e fairness\n",
    "    df_avaliacao = X_test.copy()\n",
    "    df_avaliacao['y_true'] = y_test\n",
    "    df_avaliacao['y_pred'] = y_pred\n",
    "\n",
    "    for coluna in ['Department', 'MaritalStatus','JobRole','Gender','BusinessTravel','EducationField']:\n",
    "        if coluna in df_avaliacao.columns:\n",
    "            avaliar_fairness(df_avaliacao, coluna, df_avaliacao['y_true'], df_avaliacao['y_pred'])\n",
    "\n",
    "    resultados.append({\n",
    "        'Modelo': nome,\n",
    "        'Melhores Params': melhores_params,\n",
    "        'F1-score': f1,\n",
    "        'F2-score': f2,\n",
    "        'Balanced Accuracy': bal_acc,\n",
    "        'MCC': mcc,\n",
    "        'PR AUC': pr_auc\n",
    "    })\n",
    "    \n",
    "    if nome == 'Voting Ensemble':\n",
    "        joblib.dump(grid.best_estimator_, 'melhor_modelo_Voting_Ensemble.pkl') \n",
    "\n",
    "# Tabela final\n",
    "df_resultados = pd.DataFrame(resultados).sort_values(by='F1-score', ascending=False).reset_index(drop=True)\n",
    "print(\"\\n📊 Comparativo final com métricas para desbalanceamento:\")\n",
    "print(df_resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6da094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70677273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d2f08d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e5608b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dce6ace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
